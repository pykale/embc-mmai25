{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3zwHy4Qodr-"
   },
   "source": [
    "# **Drug–Target Interaction Prediction** (non DA in domain example)\n",
    "\n",
    "Welcome to this tutorial on drug–target interaction (DTI) prediction using **PyTorch Geometric**. We demonstrate how to predict whether a given drug and protein pair interact, using graph-based deep learning.\n",
    "\n",
    "This notebook is inspired by the work of [**Bai et al. (_Nature Machine Intelligence_, 2023)**](https://www.nature.com/articles/s42256-022-00605-1), which introduced a **Deep Bilinear Attention Network (BAN)** with **adversarial domain adaptation**. The model is designed to:\n",
    "\n",
    "- **Capture fine-grained pairwise interactions** between drug molecules and target proteins\n",
    "- **Generalise to out-of-distribution data**, improving performance on unseen drug–target pairs\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 What You'll Learn\n",
    "\n",
    "- How to use `kale.loaddata.molecular_datasets.DTIDataset` encode **drugs** and **protein sequences**.\n",
    "- How to implement the **BAN** network\n",
    "- How to evaluate model performance on benchmark datasets\n",
    "\n",
    "---\n",
    "\n",
    "Let’s get started!\n",
    "\n",
    "In the following sections, we'll walk through data preprocessing, model implementation, and evaluation, showing how these components come together for DTI prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjUArFj8orRN"
   },
   "source": [
    "## Setup\n",
    "\n",
    "As a starting point, we will install the required packages and load a set of helper functions to assist throughout this tutorial. To keep the output clean and focused on interpretation, we will also suppress warnings.\n",
    "\n",
    "Moreover, we provide helper functions that can be inspected directly in the .py files located in the notebook’s current directory. The three additional helper scripts are:\n",
    "\n",
    "- `config.py`: Defines the base configuration settings, which can be overridden using a custom `.yaml` file.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b08jmwa3UCfD"
   },
   "source": [
    "[Optional] If you are using Google Colab, please using the following codes to load necessary demo data and code files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14617,
     "status": "ok",
     "timestamp": 1749656673721,
     "user": {
      "displayName": "Jiayang Zhang",
      "userId": "18316529127370915604"
     },
     "user_tz": -60
    },
    "id": "RnznUM7MUBzk",
    "outputId": "9b4bc354-7e46-487d-aebb-d71b4b62b308"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'embc-mmai25'...\n",
      "remote: Enumerating objects: 697, done.\u001B[K\n",
      "remote: Counting objects: 100% (99/99), done.\u001B[K\n",
      "remote: Compressing objects: 100% (74/74), done.\u001B[K\n",
      "remote: Total 697 (delta 44), reused 62 (delta 22), pack-reused 598 (from 1)\u001B[K\n",
      "Receiving objects: 100% (697/697), 125.59 MiB | 10.98 MiB/s, done.\n",
      "Resolving deltas: 100% (289/289), done.\n",
      "/content/embc-mmai25/tutorials/drug-target-interaction\n"
     ]
    }
   ],
   "source": [
    "!git clone --branch drug-target-interaction https://github.com/pykale/embc-mmai25.git\n",
    "%cd /content/embc-mmai25/tutorials/drug-target-interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF_TbTyyovnd"
   },
   "source": [
    "## 📦 Packages\n",
    "\n",
    "The main packages required for this tutorial are **PyKale**, **PyTorch Geometric**, and **RDKit**.\n",
    "\n",
    "- **PyKale** is an open-source interdisciplinary machine learning library developed at the University of Sheffield, designed for applications in biomedical and scientific domains.\n",
    "- **PyG** (PyTorch Geometric) is a library built on top of PyTorch for building and training Graph Neural Networks (GNNs) on structured data.\n",
    "- **RDKit** is a cheminformatics toolkit for handling and processing molecular structures, particularly useful for working with SMILES strings and molecular graphs.\n",
    "\n",
    "📄 Other dependencies are listed in [`embc-mmai25/requirements.txt`](https://github.com/pykale/embc-mmai25/blob/main/requirements.txt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tOz_81AoxO1",
    "outputId": "9ac9bda3-15d9-4719-dd8f-495c2f2d45f9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m779.2/779.2 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m66.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m60.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.2/176.2 MB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.1/168.1 MB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m114.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.1/823.1 kB\u001B[0m \u001B[31m59.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.4/7.4 MB\u001B[0m \u001B[31m126.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.0/7.0 MB\u001B[0m \u001B[31m125.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m962.5/962.5 kB\u001B[0m \u001B[31m58.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for pykale (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet git+https://github.com/pykale/pykale@main\\\n",
    "    && echo \"PyKale installed successfully ✅\" \\\n",
    "    || echo \"Failed to install PyKale ❌\"\n",
    "\n",
    "!pip install --quiet -r /content/embc-mmai25/requirements.txt \\\n",
    "    && echo \"Required packages installed successfully ✅\" \\\n",
    "    || echo \"Failed to install required packages ❌\"\n",
    "\n",
    "!pip install --upgrade --force-reinstall numpy\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git \\\n",
    "    && echo \"PyG installed successfully ✅\" \\\n",
    "    || echo \"Failed to install PyG ❌\"\n",
    "\n",
    "!pip install rdkit-pypi \\\n",
    "    && echo \"PyG installed successfully ✅\" \\\n",
    "    || echo \"Failed to install PyG ❌\""
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Yt8JjTTxe8NA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "id": "SNOjMyfAfplW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnUX29xrrjXW"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "# PyKale and custom modules (make sure your PYTHONPATH is set correctly)\n",
    "from kale.loaddata.molecular_datasets import DTIDataset, graph_collate_func\n",
    "from kale.embed.ban import DrugBAN\n",
    "from kale.pipeline.drugban_trainer import DrugbanTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obCd7DXipiLr"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "To minimize the footprint of the notebook when specifying configurations, we provide a `config.py` file that defines default parameters. These can be customized by supplying a `.yaml` configuration file, such as `experiments/non_da_in_domain.yaml` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_S6T1HQp3cy"
   },
   "outputs": [],
   "source": [
    "from configs import get_cfg_defaults\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"experiments/non_DA_in_domain.yaml\")\n",
    "\n",
    "# temporary to shorten training time\n",
    "cfg.SOLVER.MAX_EPOCH = 2\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQp2-BIyqEop"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "We use the DTI benchmark dataset BindingDB, provided by the authors of the DrugBAN paper in their [repository](https://github.com/peizhenbai/DrugBAN/tree/main).\n",
    "\n",
    "The `bindingdb` dataset is structured as follows:\n",
    "\n",
    "```sh\n",
    "    ├───bindingdb\n",
    "    │   ├───cluster\n",
    "    │   │   ├───source_train.csv\n",
    "    │   │   ├───target_train.csv\n",
    "    │   │   ├───target_test.csv\n",
    "    │   ├───random\n",
    "    │   │   ├───test.csv\n",
    "    │   │   ├───train.csv\n",
    "    │   │   ├───val.csv\n",
    "    │   ├───full.csv\n",
    "\n",
    "```\n",
    "\n",
    "Each CSV file contains the following columns:\n",
    "\n",
    "- **SMILES**: Drug molecule represented in SMILES (Simplified Molecular Input Line Entry System) format  \n",
    "- **Protein Sequence**: Protein represented as an amino acid sequence  \n",
    "- **Y**: Binary interaction label (`1` = interaction, `0` = no interaction)\n",
    "\n",
    "\n",
    "An example structure of the BindingDB dataset is shown below.\n",
    "\n",
    "**Table 1**: Characteristics of the BindingDB DTI dataset.\n",
    "\n",
    "| SMILES             | Protein Sequence         | Y |\n",
    "|--------------------|--------------------------|---|\n",
    "| Fc1ccc(C2(COC…)    | MDNVLPVDSDLS…            | 1 |\n",
    "| O=c1oc2c(O)c(…)    | MMYSKLLTLTTL…            | 0 |\n",
    "| CC(C)Oc1cc(N…)     | MGMACLTMTEME…            | 1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "\n",
    "- **Drugs** are converted from SMILES strings to molecular graphs using **RDKit** and **PyTorch Geometric**.  \n",
    "- **Proteins** are encoded as integer sequences (via one-hot encoding or embeddings).  \n",
    "- **Labels** are binary (`0` or `1`).\n",
    "\n",
    "The `DTIDataset` class handles this preprocessing pipeline.\n"
   ],
   "metadata": {
    "id": "caJ2PQ8slcbn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kale.loaddata.molecular_datasets import DTIDataset\n",
    "\n",
    "dataFolder = os.path.join(f\"./datasets/{cfg.DATA.DATASET}\", str(cfg.DATA.SPLIT))\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dataFolder, \"train.csv\"))\n",
    "df_val = pd.read_csv(os.path.join(dataFolder, \"val.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(dataFolder, \"test.csv\"))\n",
    "\n",
    "train_dataset = DTIDataset(df_train.index.values, df_train)\n",
    "valid_dataset = DTIDataset(df_val.index.values, df_val)\n",
    "test_dataset = DTIDataset(df_test.index.values, df_test)"
   ],
   "metadata": {
    "id": "dXUrnVp4eZeB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Inspection\n",
    "\n",
    "After loading the dataset, we can quickly inspect its structure and contents using the following code:\n"
   ],
   "metadata": {
    "id": "ddpFbAbsiobu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "print(\"Example sample:\\n\", train_dataset[0])"
   ],
   "metadata": {
    "id": "-Yp4PaF-iXBf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batching\n",
    "\n",
    "We use PyTorch’s `DataLoader` to efficiently load molecular graph data in batches. A custom `graph_collate_func` is used to correctly batch variable-sized graph structures. Separate data loaders are created for training (with shuffling) and for validation/test (without shuffling).\n"
   ],
   "metadata": {
    "id": "NQIdSyTsmEul"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from kale.loaddata.molecular_datasets import graph_collate_func\n",
    "\n",
    "params = {\n",
    "        \"batch_size\": cfg.SOLVER.BATCH_SIZE,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": cfg.SOLVER.NUM_WORKERS,\n",
    "        \"drop_last\": True,\n",
    "        \"collate_fn\": graph_collate_func,\n",
    "    }\n",
    "\n",
    "\n",
    "training_generator = DataLoader(train_dataset, **params)\n",
    "params.update({\"shuffle\": False, \"drop_last\": False})\n",
    "valid_generator = DataLoader(valid_dataset, **params)\n",
    "test_generator = DataLoader(test_dataset, **params)"
   ],
   "metadata": {
    "id": "Wy8snw8-gPjk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9uygzHruxzW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOF4iCG_u9Dd"
   },
   "source": [
    "## Setup Model\n",
    "\n",
    "The **DrugBAN** model consists of the following components:\n",
    "\n",
    "- A **GCN** for drug molecular graphs  \n",
    "- A **CNN** for protein sequences  \n",
    "- A **Bilinear Attention Network (BAN)** for feature fusion  \n",
    "- An **MLP** for classification\n",
    "\n",
    "Model configuration is managed via the `config.py` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voyFdDmuu_C9"
   },
   "outputs": [],
   "source": [
    "from kale.embed.ban import DrugBAN\n",
    "\n",
    "model = DrugBAN(**cfg)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eQX2eAXvB9l"
   },
   "source": [
    "## Setup Trainer\n",
    "We use a PyTorch Lightning trainer for structured training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7tbp8pkvDb1"
   },
   "outputs": [],
   "source": [
    "from kale.pipeline.drugban_trainer import DrugbanTrainer\n",
    "\n",
    "drugban_trainer = DrugbanTrainer(\n",
    "    model=DrugBAN(**cfg),\n",
    "    solver_lr=cfg[\"SOLVER\"][\"LEARNING_RATE\"],\n",
    "    num_classes=cfg[\"DECODER\"][\"BINARY\"],\n",
    "    batch_size=cfg[\"SOLVER\"][\"BATCH_SIZE\"],\n",
    "    # --- domain adaptation parameters ---\n",
    "    is_da=cfg[\"DA\"][\"USE\"],\n",
    "    solver_da_lr=cfg[\"SOLVER\"][\"DA_LEARNING_RATE\"],\n",
    "    da_init_epoch=cfg[\"DA\"][\"INIT_EPOCH\"],\n",
    "    da_method=cfg[\"DA\"][\"METHOD\"],\n",
    "    original_random=cfg[\"DA\"][\"ORIGINAL_RANDOM\"],\n",
    "    use_da_entropy=cfg[\"DA\"][\"USE_ENTROPY\"],\n",
    "    da_random_layer=cfg[\"DA\"][\"RANDOM_LAYER\"],\n",
    "    # --- discriminator parameters ---\n",
    "    da_random_dim=cfg[\"DA\"][\"RANDOM_DIM\"],\n",
    "    decoder_in_dim=cfg[\"DECODER\"][\"IN_DIM\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=\"{epoch}-{step}-{val_BinaryAUROC:.4f}\",\n",
    "    monitor=\"val_BinaryAUROC\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    max_epochs=cfg[\"SOLVER\"][\"MAX_EPOCH\"],\n",
    "    deterministic=True,  # for reproducibility\n",
    ")"
   ],
   "metadata": {
    "id": "Z8Q3r0QGnseR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "xDcpepJJoiyn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.fit(drugban_trainer, train_dataloaders=training_generator, val_dataloaders=valid_generator)"
   ],
   "metadata": {
    "id": "yqMEMTuSokyf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing\n",
    "\n",
    "### Results and Interpretation\n",
    "\n",
    "After training, you can inspect evaluation metrics such as **AUROC**, **F1 score**, **Recall**, and others.  \n",
    "You can also visualise **attention maps** or **feature importances** as needed for interpretation."
   ],
   "metadata": {
    "id": "dJ-SZyCfomFH"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxT6SMKsvNtN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.test(drugban_trainer, dataloaders=test_generator, ckpt_path=\"best\")"
   ],
   "metadata": {
    "id": "rjIYeRWNooQv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fMUF0iivT1E"
   },
   "source": [
    "## Summary\n",
    "\n",
    "- We loaded and preprocessed the **BindingDB** dataset for DTI prediction.  \n",
    "- We built a **DrugBAN** model using **GCN**, **CNN**, and **BAN** components.  \n",
    "- We trained and evaluated the model using **PyTorch Lightning**.  \n",
    "- The configuration file allows for easy reproduction and modification of experiments.  \n",
    "\n",
    "For more details, see the [original codebase](https://github.com/peizhenbai/DrugBAN) and the accompanying paper in *Nature Machine Intelligence*.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "caJ2PQ8slcbn",
    "ddpFbAbsiobu"
   ],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyOVSf1UHgzpaosvedLrL4WE"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
