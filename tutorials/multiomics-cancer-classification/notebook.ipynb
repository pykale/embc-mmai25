{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kumO84BCwsyB"
      },
      "source": [
        "# Cancer Classification\n",
        "\n",
        "In this tutorial, we demonstrate how to integrate **patient multiomics data** to enhance **cancer classification**.\n",
        "\n",
        "This notebook builds on the work of **Wang et al. (Nature Communication, 2021)**, which present a novel multi-omics integrative method named **M**ulti-**O**mics **G**raph c**O**nvolutional **NET**works (MOGONET) and jointly explores omics-specific learning and cross-omics correlation learning for effective multiomics data classification by including mRNA expression data, DNA methylation data, and microRNA expression data.\n",
        "\n",
        "---\n",
        "\n",
        "**Objective**\n",
        "\n",
        "TBC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqcLga9rwsyC"
      },
      "source": [
        "# Setup\n",
        "\n",
        "As a starting point, we will install the required packages and load a set of helper functions to assist throughout this tutorial. To keep the output clean and focused on interpretation, we will also suppress warnings.\n",
        "\n",
        "Moreover, we provide helper functions that can be inspected directly in the `.py` files located in the notebook’s current directory. The three additional helper scripts are:\n",
        "- `config.py`: Defines the base configuration settings, which can be overridden using a custom `.yaml` file.\n",
        "- `parsing.py`: Contains utilities to compile evaluation results from the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmINSfE8wsyC",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOg0TjsryjBg"
      },
      "source": [
        "[Optional] If you are using Google Colab, please using the following codes to load necessary demo data and code files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ujxrI6OcIl",
        "outputId": "7636006d-8db8-4d9a-c682-c85878cefb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'embc-mmai25' already exists and is not an empty directory.\n",
            "/content/embc-mmai25/tutorials/multiomics-cancer-classification\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch multiomics https://github.com/pykale/embc-mmai25.git\n",
        "%cd /content/embc-mmai25/tutorials/multiomics-cancer-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvqfMBgvwsyD"
      },
      "source": [
        "## Packages\n",
        "\n",
        "The main packages required for this tutorialare PyKale and PyTorch Geometric.\n",
        "\n",
        "**PyKale** is an open-source interdisciplinary machine learning library developed at the University of Sheffield, with a focus on applications in biomedical and scientific domains.\n",
        "\n",
        "**PyG** (PyTorch Geometric) is a library built upon  PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\n",
        "\n",
        "Other required packages can be found in `embc-mmai25/requirements.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9s94AAdwsyD",
        "outputId": "c79c3db4-385e-4b73-b6b8-ab46d445d0e9",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mPyKale installed successfully ✅\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Required packages installed successfully ✅\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pykale 0.1.2 requires numpy<2.0.0, but you have numpy 2.3.0 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "PyG installed successfully ✅\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet git+https://github.com/pykale/pykale@main\\\n",
        "    && echo \"PyKale installed successfully ✅\" \\\n",
        "    || echo \"Failed to install PyKale ❌\"\n",
        "!pip install --quiet -r /content/embc-mmai25/requirements.txt \\\n",
        "    && echo \"Required packages installed successfully ✅\" \\\n",
        "    || echo \"Failed to install required packages ❌\"\n",
        "!pip install --upgrade --force-reinstall numpy\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git \\\n",
        "    && echo \"PyG installed successfully ✅\" \\\n",
        "    || echo \"Failed to install PyG ❌\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8PV9BzBwsyE"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "To minimize the footprint of the notebook when specifying configurations, we provide a `config.py` file that defines default parameters. These can be customized by supplying a `.yaml` configuration file, such as `experiments/base.yaml` as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJquEeGSw2RV",
        "outputId": "28339564-98e0-42b8-aaea-1100592e6c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATASET:\n",
            "  NAME: TCGA_BRCA\n",
            "  NUM_CLASSES: 5\n",
            "  NUM_MODALITIES: 3\n",
            "  RANDOM_SPLIT: False\n",
            "  ROOT: dataset/\n",
            "  URL: https://github.com/pykale/data/raw/main/multiomics/TCGA_BRCA.zip\n",
            "MODEL:\n",
            "  EDGE_PER_NODE: 10\n",
            "  EQUAL_WEIGHT: False\n",
            "  GCN_DROPOUT_RATE: 0.5\n",
            "  GCN_HIDDEN_DIM: [400, 400, 200]\n",
            "  GCN_LR: 0.0005\n",
            "  GCN_LR_PRETRAIN: 0.001\n",
            "  VCDN_LR: 0.001\n",
            "OUTPUT:\n",
            "  OUT_DIR: ./outputs\n",
            "SOLVER:\n",
            "  MAX_EPOCHS: 500\n",
            "  MAX_EPOCHS_PRETRAIN: 5\n",
            "  SEED: 2023\n"
          ]
        }
      ],
      "source": [
        "from config import get_cfg_defaults\n",
        "\n",
        "cfg = get_cfg_defaults()\n",
        "cfg.merge_from_file(\"experiments/base.yaml\")\n",
        "# cfg.freeze()\n",
        "cfg.SOLVER.MAX_EPOCHS = 500\n",
        "cfg.DATASET.NUM_MODALITIES = 3\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PGPOnz021Xt"
      },
      "source": [
        "# Data Loading\n",
        "\n",
        "We use the preprocessed multiomics benchmark, BRCA, which have been provided by the authors of MOGONET paper in [their repository](https://github.com/txWang/MOGONET).\n",
        "A brief description of BRCA dataset is shown in the following\n",
        "table.\n",
        "\n",
        "**Table 1**: Characteristics of the preprocessed BRCA multiomics dataset.\n",
        "\n",
        "|      Omics       | #Training samples | #Test samples | #Features |\n",
        "|:----------------:|:-----------------:|:-------------:|:---------:|\n",
        "| mRNA expression  |        612        |      263      |   1000    |\n",
        "| DNA methylation  |        612        |      263      |   1000    |\n",
        "| miRNA expression |        612        |      263      |    503    |\n",
        "\n",
        "Note: These datasets have been processed following the **Preprocessing** section of the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WGYLfi35ah7",
        "outputId": "fd974f8a-25cd-4228-e588-4d0b5f87625f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==> Preparing dataset...\n",
            "\n",
            "Dataset info:\n",
            "   number of modalities: 3\n",
            "   number of classes: 5\n",
            "\n",
            "   modality | total samples | num train | num test  | num features\n",
            "   -----------------------------------------------------------------\n",
            "   1        | 875           | 612       | 263       | 1000        \n",
            "   2        | 875           | 612       | 263       | 1000        \n",
            "   3        | 875           | 612       | 263       | 503         \n",
            "   -----------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from kale.loaddata.multiomics_datasets import SparseMultiomicsDataset\n",
        "from kale.prepdata.tabular_transform import ToOneHotEncoding, ToTensor\n",
        "\n",
        "print(\"\\n==> Preparing dataset...\")\n",
        "file_names = []\n",
        "for modality in range(1, cfg.DATASET.NUM_MODALITIES + 1):\n",
        "    file_names.append(f\"{modality}_tr.csv\")\n",
        "    file_names.append(f\"{modality}_lbl_tr.csv\")\n",
        "    file_names.append(f\"{modality}_te.csv\")\n",
        "    file_names.append(f\"{modality}_lbl_te.csv\")\n",
        "\n",
        "multiomics_data = SparseMultiomicsDataset(\n",
        "    root=cfg.DATASET.ROOT,\n",
        "    raw_file_names=file_names,\n",
        "    num_modalities=cfg.DATASET.NUM_MODALITIES,\n",
        "    num_classes=cfg.DATASET.NUM_CLASSES,\n",
        "    edge_per_node=cfg.MODEL.EDGE_PER_NODE,\n",
        "    url=cfg.DATASET.URL,\n",
        "    random_split=cfg.DATASET.RANDOM_SPLIT,\n",
        "    equal_weight=cfg.MODEL.EQUAL_WEIGHT,\n",
        "    pre_transform=ToTensor(dtype=torch.float),\n",
        "    target_pre_transform=ToOneHotEncoding(dtype=torch.float),\n",
        ")\n",
        "\n",
        "print(multiomics_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "j_iJzXGjnh1N"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Author: Sina Tabakhi, sina.tabakhi@gmail.com\n",
        "# =============================================================================\n",
        "\n",
        "\"\"\"\n",
        "Construct a pipeline to run the MOGONET method based on PyTorch Lightning. MOGONET is a multiomics fusion framework for\n",
        "cancer classification and biomarker identification that utilizes supervised graph convolutional networks for omics\n",
        "datasets.\n",
        "\n",
        "This code is written by refactoring the MOGONET code (https://github.com/txWang/MOGONET/blob/main/train_test.py)\n",
        "within the PyTorch Lightning.\n",
        "\n",
        "Reference:\n",
        "Wang, T., Shao, W., Huang, Z., Tang, H., Zhang, J., Ding, Z., Huang, K. (2021). MOGONET integrates multi-omics data\n",
        "using graph convolutional networks allowing patient classification and biomarker identification. Nature communications.\n",
        "https://www.nature.com/articles/s41467-021-23774-w\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from torch import Tensor\n",
        "from torch.nn import CrossEntropyLoss, ModuleList\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_sparse import SparseTensor\n",
        "\n",
        "from kale.embed.mogonet import MogonetGCN\n",
        "from kale.loaddata.multiomics_datasets import SparseMultiomicsDataset\n",
        "from kale.predict.decode import LinearClassifier, VCDN\n",
        "\n",
        "\n",
        "class MultiomicsTrainer(pl.LightningModule):\n",
        "    r\"\"\"The PyTorch Lightning implementation of the MOGONET method, a multiomics fusion method designed for\n",
        "    classification tasks.\n",
        "\n",
        "    Args:\n",
        "        dataset (SparseMultiomicsDataset): The input dataset created in form of :class:`~torch_geometric.data.Dataset`.\n",
        "        num_modalities (int): The total number of modalities in the dataset.\n",
        "        num_classes (int): The total number of classes in the dataset.\n",
        "        unimodal_encoder (List[MogonetGCN]): The list of GCN encoders for each modality.\n",
        "        unimodal_decoder (List[LinearClassifier]): The list of linear classifier decoders for each modality.\n",
        "        loss_fn (CrossEntropyLoss): The loss function used to gauge the error between the prediction outputs and the\n",
        "            provided target values.\n",
        "        multimodal_decoder (VCDN, optional): The VCDN decoder used in the multiomics dataset.\n",
        "            (default: ``None``)\n",
        "        train_multimodal_decoder (bool, optional): Whether to train VCDN module. (default: ``True``)\n",
        "        gcn_lr (float, optional): The learning rate used in the GCN module. (default: 5e-4)\n",
        "        vcdn_lr (float, optional): The learning rate used in the VCDN module. (default: 1e-3)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset: SparseMultiomicsDataset,\n",
        "        num_modalities: int,\n",
        "        num_classes: int,\n",
        "        unimodal_encoder: List[MogonetGCN],\n",
        "        unimodal_decoder: List[LinearClassifier],\n",
        "        loss_fn: CrossEntropyLoss,\n",
        "        multimodal_decoder: Optional[VCDN] = None,\n",
        "        train_multimodal_decoder: bool = True,\n",
        "        gcn_lr: float = 5e-4,\n",
        "        vcdn_lr: float = 1e-3,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.num_modalities = num_modalities\n",
        "        self.num_classes = num_classes\n",
        "        self.unimodal_encoder = ModuleList(unimodal_encoder)\n",
        "        self.unimodal_decoder = ModuleList(unimodal_decoder)\n",
        "        self.multimodal_decoder = multimodal_decoder\n",
        "        self.train_multimodal_decoder = train_multimodal_decoder\n",
        "        self.loss_fn = loss_fn\n",
        "        self.gcn_lr = gcn_lr\n",
        "        self.vcdn_lr = vcdn_lr\n",
        "\n",
        "        # activate manual optimization\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "    def configure_optimizers(self) -> List[Optimizer]:\n",
        "        \"\"\"Return the optimizers used during training.\"\"\"\n",
        "        optimizers = []\n",
        "\n",
        "        for modality in range(self.num_modalities):\n",
        "            optimizers.append(\n",
        "                torch.optim.Adam(\n",
        "                    list(self.unimodal_encoder[modality].parameters())\n",
        "                    + list(self.unimodal_decoder[modality].parameters()),\n",
        "                    lr=self.gcn_lr,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if self.multimodal_decoder is not None:\n",
        "            optimizers.append(torch.optim.Adam(self.multimodal_decoder.parameters(), lr=self.vcdn_lr))\n",
        "\n",
        "\n",
        "        return optimizers\n",
        "\n",
        "    def forward(\n",
        "        self, x: List[Tensor], adj_t: List[SparseTensor], multimodal: bool = False\n",
        "    ) -> Union[Tensor, List[Tensor]]:\n",
        "        \"\"\"Same as :meth:`torch.nn.Module.forward()`.\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If `multimodal_decoder` is `None` for multiomics datasets.\n",
        "        \"\"\"\n",
        "        output = []\n",
        "\n",
        "        for modality in range(self.num_modalities):\n",
        "            output.append(\n",
        "                self.unimodal_decoder[modality](self.unimodal_encoder[modality](x[modality], adj_t[modality]))\n",
        "            )\n",
        "\n",
        "        if not multimodal:\n",
        "            return output\n",
        "\n",
        "        if self.multimodal_decoder is not None:\n",
        "            return self.multimodal_decoder(output)\n",
        "\n",
        "        raise TypeError(\"multimodal_decoder must be defined for multiomics datasets.\")\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx: int):\n",
        "        \"\"\"Compute and return the training loss.\n",
        "\n",
        "        Args:\n",
        "            train_batch (:class:`~torch.Tensor` | (:class:`~torch.Tensor`, ...) | [:class:`~torch.Tensor`, ...]):\n",
        "                The output of your :class:`~torch.utils.data.DataLoader`. A tensor, tuple or list.\n",
        "            batch_idx (``int``): Integer displaying index of this batch.\n",
        "        \"\"\"\n",
        "        optimizer = self.optimizers()\n",
        "\n",
        "        if not isinstance(optimizer, (list, tuple)):\n",
        "            optimizer = [optimizer]\n",
        "\n",
        "\n",
        "        x = []\n",
        "        adj_t = []\n",
        "        y = []\n",
        "        sample_weight = []\n",
        "        for modality in range(self.num_modalities):\n",
        "            data = train_batch[modality]\n",
        "            x.append(data.x[data.train_idx])\n",
        "            adj_t.append(data.adj_t_train)\n",
        "            y.append(data.y[data.train_idx])\n",
        "            sample_weight.append(data.train_sample_weight)\n",
        "\n",
        "        outputs = self.forward(x, adj_t, multimodal=False)\n",
        "\n",
        "        for modality in range(self.num_modalities):\n",
        "            loss = self.loss_fn(outputs[modality], y[modality])\n",
        "            loss = torch.mean(torch.mul(loss, sample_weight[modality]))\n",
        "            self.logger.log_metrics({f\"train_unimodal_step_loss ({modality + 1})\": loss.detach()}, self.global_step)\n",
        "\n",
        "            optimizer[modality].zero_grad()\n",
        "            self.manual_backward(loss)\n",
        "            optimizer[modality].step()\n",
        "\n",
        "        if self.train_multimodal_decoder and self.multimodal_decoder is not None:\n",
        "            output = self.forward(x, adj_t, multimodal=True)\n",
        "            multi_loss = self.loss_fn(output, y[0])\n",
        "            multi_loss = torch.mean(torch.mul(multi_loss, sample_weight[0]))\n",
        "            self.logger.log_metrics({\"train_multimodal_step_loss\": multi_loss.detach()}, self.global_step)\n",
        "\n",
        "            optimizer[-1].zero_grad()\n",
        "            self.manual_backward(multi_loss)\n",
        "            optimizer[-1].step()\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx: int):\n",
        "        \"\"\"Compute and return the test loss.\n",
        "\n",
        "        Args:\n",
        "            test_batch (:class:`~torch.Tensor` | (:class:`~torch.Tensor`, ...) | [:class:`~torch.Tensor`, ...]):\n",
        "                The output of your :class:`~torch.utils.data.DataLoader`. A tensor, tuple or list.\n",
        "            batch_idx (int): Integer displaying index of this batch.\n",
        "        \"\"\"\n",
        "        x = []\n",
        "        adj_t = []\n",
        "        y = []\n",
        "        for modality in range(self.num_modalities):\n",
        "            data = test_batch[modality]\n",
        "            x.append(data.x)\n",
        "            adj_t.append(data.adj_t)\n",
        "            y.append(torch.argmax(data.y[data.test_idx], dim=1))\n",
        "\n",
        "        if self.multimodal_decoder is not None:\n",
        "            output = self.forward(x, adj_t, multimodal=True)\n",
        "        else:\n",
        "            output = self.forward(x, adj_t, multimodal=False)[0]\n",
        "\n",
        "        pred_test_data = torch.index_select(output, dim=0, index=test_batch[0].test_idx)\n",
        "        final_output = F.softmax(pred_test_data, dim=1).detach().cpu().numpy()\n",
        "        actual_output = y[0].detach().cpu()\n",
        "\n",
        "        if self.num_classes == 2:\n",
        "            self.log(\"Accuracy\", round(accuracy_score(actual_output, final_output.argmax(1)), 3))\n",
        "            self.log(\"F1\", round(f1_score(actual_output, final_output.argmax(1)), 3))\n",
        "            self.log(\"AUC\", round(roc_auc_score(actual_output, final_output[:, 1]), 3))\n",
        "        else:\n",
        "            self.log(\"Accuracy\", round(accuracy_score(actual_output, final_output.argmax(1)), 3))\n",
        "            self.log(\"F1 weighted\", round(f1_score(actual_output, final_output.argmax(1), average=\"weighted\"), 3))\n",
        "            self.log(\"F1 macro\", round(f1_score(actual_output, final_output.argmax(1), average=\"macro\"), 3))\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def _custom_data_loader(self) -> DataLoader:\n",
        "        \"\"\"Return an iterable or a collection of iterables that specifies all the samples in the dataset.\"\"\"\n",
        "        dataloaders = DataLoader(self.dataset, batch_size=1)\n",
        "        return dataloaders\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        \"\"\"Return an iterable or a collection of iterables that specifies training samples in the dataset.\"\"\"\n",
        "        return self._custom_data_loader()\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        \"\"\"Return an iterable or a collection of iterables that specifies test samples in the dataset.\"\"\"\n",
        "        return self._custom_data_loader()\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        r\"\"\"Returns a string representation of the multiomics trainer object.\n",
        "\n",
        "        Returns:\n",
        "            str: The string representation of the multiomics trainer object.\n",
        "        \"\"\"\n",
        "        model_str = [\"\\nModel info:\\n\", \"   Unimodal encoder:\\n\"]\n",
        "\n",
        "        for modality in range(self.num_modalities):\n",
        "            model_str.append(f\"    ({modality + 1}) {self.unimodal_encoder[modality]}\")\n",
        "\n",
        "        model_str.append(\"\\n\\n  Unimodal decoder:\\n\")\n",
        "        for modality in range(self.num_modalities):\n",
        "            model_str.append(f\"    ({modality + 1}) {self.unimodal_decoder[modality]}\")\n",
        "\n",
        "        if self.multimodal_decoder is not None:\n",
        "            model_str.append(\"\\n\\n  Multimodal decoder:\\n\")\n",
        "            model_str.append(f\"    {self.multimodal_decoder}\")\n",
        "\n",
        "        return \"\".join(model_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "amqFg4jTnd18"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from yacs.config import CfgNode\n",
        "\n",
        "from kale.embed.mogonet import MogonetGCN\n",
        "from kale.loaddata.multiomics_datasets import SparseMultiomicsDataset\n",
        "# from kale.pipeline.multiomics_trainer import MultiomicsTrainer\n",
        "from kale.predict.decode import LinearClassifier, VCDN\n",
        "\n",
        "\n",
        "class MogonetModel:\n",
        "    r\"\"\"Setup the MOGONET model via the config file.\n",
        "\n",
        "    Args:\n",
        "        cfg (CfgNode): A YACS config object.\n",
        "        dataset (SparseMultiomicsDataset): The input dataset created in form of :class:`~torch_geometric.data.Dataset`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: CfgNode, dataset: SparseMultiomicsDataset) -> None:\n",
        "        self.cfg = cfg\n",
        "        self.dataset = dataset\n",
        "        self.unimodal_encoder: List[MogonetGCN] = []\n",
        "        self.unimodal_decoder: List[LinearClassifier] = []\n",
        "        self.multimodal_decoder: Optional[VCDN] = None\n",
        "        self.loss_function = CrossEntropyLoss(reduction=\"none\")\n",
        "        self._create_model()\n",
        "\n",
        "    def _create_model(self) -> None:\n",
        "        \"\"\"Create the MOGONET model via the config file.\"\"\"\n",
        "        num_modalities = self.cfg.DATASET.NUM_MODALITIES\n",
        "        num_classes = self.cfg.DATASET.NUM_CLASSES\n",
        "        gcn_dropout_rate = self.cfg.MODEL.GCN_DROPOUT_RATE\n",
        "        gcn_hidden_dim = self.cfg.MODEL.GCN_HIDDEN_DIM\n",
        "        vcdn_hidden_dim = pow(num_classes, num_modalities)\n",
        "\n",
        "        for modality in range(num_modalities):\n",
        "            self.unimodal_encoder.append(\n",
        "                MogonetGCN(\n",
        "                    in_channels=self.dataset.get(modality).num_features,\n",
        "                    hidden_channels=gcn_hidden_dim,\n",
        "                    dropout=gcn_dropout_rate,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            self.unimodal_decoder.append(LinearClassifier(in_dim=gcn_hidden_dim[-1], out_dim=num_classes))\n",
        "\n",
        "        if num_modalities >= 2:\n",
        "          self.multimodal_decoder = VCDN(\n",
        "              num_modalities=num_modalities, num_classes=num_classes, hidden_dim=vcdn_hidden_dim\n",
        "          )\n",
        "\n",
        "    def get_model(self, pretrain: bool = False) -> MultiomicsTrainer:\n",
        "        \"\"\"Return the prepared MOGONET model based on user preference.\n",
        "\n",
        "        Args:\n",
        "            pretrain (bool, optional): Whether to return the pretrain model. (default: ``False``)\n",
        "\n",
        "        Returns:\n",
        "            MultiomicsTrainer: The prepared MOGONET model.\n",
        "        \"\"\"\n",
        "        num_modalities = self.cfg.DATASET.NUM_MODALITIES\n",
        "        num_classes = self.cfg.DATASET.NUM_CLASSES\n",
        "        gcn_lr_pretrain = self.cfg.MODEL.GCN_LR_PRETRAIN\n",
        "        gcn_lr = self.cfg.MODEL.GCN_LR\n",
        "        vcdn_lr = self.cfg.MODEL.VCDN_LR\n",
        "\n",
        "        if pretrain:\n",
        "            multimodal_model = None\n",
        "            train_multimodal_decoder = False\n",
        "            gcn_lr = gcn_lr_pretrain\n",
        "        else:\n",
        "            multimodal_model = self.multimodal_decoder\n",
        "            train_multimodal_decoder = True\n",
        "            gcn_lr = gcn_lr\n",
        "\n",
        "        model = MultiomicsTrainer(\n",
        "            dataset=self.dataset,\n",
        "            num_modalities=num_modalities,\n",
        "            num_classes=num_classes,\n",
        "            unimodal_encoder=self.unimodal_encoder,\n",
        "            unimodal_decoder=self.unimodal_decoder,\n",
        "            loss_fn=self.loss_function,\n",
        "            multimodal_decoder=multimodal_model,\n",
        "            train_multimodal_decoder=train_multimodal_decoder,\n",
        "            gcn_lr=gcn_lr,\n",
        "            vcdn_lr=vcdn_lr,\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        r\"\"\"Returns a string representation of the model object.\n",
        "\n",
        "        Returns:\n",
        "            str: The string representation of the model object.\n",
        "        \"\"\"\n",
        "        return self.get_model().__str__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Qx1XUAQ1pg"
      },
      "source": [
        "# Setup Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rNB4-bWRle5",
        "outputId": "496899c5-8263-4f5b-ccae-c541e49b43c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model info:\n",
            "   Unimodal encoder:\n",
            "    (1) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (2) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (3) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(503, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")\n",
            "\n",
            "  Unimodal decoder:\n",
            "    (1) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (2) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (3) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "  Multimodal decoder:\n",
            "    VCDN(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=125, out_features=125, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.25)\n",
            "    (2): Linear(in_features=125, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# from model import MogonetModel\n",
        "import pytorch_lightning as pl\n",
        "mogonet_model = MogonetModel(cfg, dataset=multiomics_data)\n",
        "print(mogonet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "napKHypFRCJs"
      },
      "source": [
        "# Setup Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR_UtRpSqwn7",
        "outputId": "dd2bb530-2930-4768-e323-88cd43b1da3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model info:\n",
            "   Unimodal encoder:\n",
            "    (1) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (2) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (3) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(503, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")\n",
            "\n",
            "  Unimodal decoder:\n",
            "    (1) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (2) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (3) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "  Multimodal decoder:\n",
            "    VCDN(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=125, out_features=125, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.25)\n",
            "    (2): Linear(in_features=125, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "network = mogonet_model.get_model(pretrain=False)\n",
        "print(network)\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
        "    default_root_dir=cfg.OUTPUT.OUT_DIR,\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    enable_model_summary=False,\n",
        "    log_every_n_steps=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c3cbb76dc9734911920a08cb644566e0",
            "302d3aa25c4941579a398792f59727b8",
            "d9cf8b7505dd420993f6769a8b1d2a7e",
            "6715df5767e24ecfb87717e9a2a4e38d",
            "765a998f3e5f4b28acc61b7d8ea3c853",
            "168bdadb28d04fdfbaa288abeaff4830",
            "a7d84eaff9b04a19825c5e1325ad8f99",
            "ad2a78246a954825b7fda05a6a2d30bf",
            "bd1499d8f5eb451c88c4542dbc1eb1c2",
            "ed15d627de704879af025081685882c0",
            "3726cdf9a7eb4458adcbada151141b90"
          ]
        },
        "id": "hdxsDxIaREMA",
        "outputId": "e10f06ba-4b54-407c-d2a0-222db2485df9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3cbb76dc9734911920a08cb644566e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=500` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "a571e5d4de564cbeaad0094ff9726639",
            "0494c2b5fa2f49669bd34b9641680121",
            "9bafd9f7095945a6884f18c21e3d2ba0",
            "8dae503195a64c099e70ef7d232e0f2c",
            "d9aa9556a8cd435592534d5617818c82",
            "ff46e36ebbbe41f3baf52b4ea08628bf",
            "c4f00450e0c8475ab9a79788560e1b9b",
            "445e85556b9940c8a6327f391c6f1445",
            "28dd0e44b2bd415392d8955deaaba5d0",
            "c00ae83daba543a09fa8000c6e37f7e4",
            "a1941c9d46b64972a2ec3ea1a12f568e"
          ]
        },
        "id": "InT2gqKlqyLD",
        "outputId": "e88e549f-d154-4f5f-a245-28b3266bf103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==> Testing model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a571e5d4de564cbeaad0094ff9726639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         Accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49799999594688416    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         F1 macro          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13300000131130219    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        F1 weighted        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3310000002384186     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        Accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49799999594688416   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        F1 macro         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13300000131130219   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       F1 weighted       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3310000002384186    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n==> Testing model...\")\n",
        "_ = trainer.test(network)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0494c2b5fa2f49669bd34b9641680121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff46e36ebbbe41f3baf52b4ea08628bf",
            "placeholder": "​",
            "style": "IPY_MODEL_c4f00450e0c8475ab9a79788560e1b9b",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "168bdadb28d04fdfbaa288abeaff4830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28dd0e44b2bd415392d8955deaaba5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "302d3aa25c4941579a398792f59727b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_168bdadb28d04fdfbaa288abeaff4830",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d84eaff9b04a19825c5e1325ad8f99",
            "value": "Epoch 499: 100%"
          }
        },
        "3726cdf9a7eb4458adcbada151141b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445e85556b9940c8a6327f391c6f1445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6715df5767e24ecfb87717e9a2a4e38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed15d627de704879af025081685882c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3726cdf9a7eb4458adcbada151141b90",
            "value": " 1/1 [00:00&lt;00:00,  3.52it/s, v_num=18]"
          }
        },
        "765a998f3e5f4b28acc61b7d8ea3c853": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8dae503195a64c099e70ef7d232e0f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00ae83daba543a09fa8000c6e37f7e4",
            "placeholder": "​",
            "style": "IPY_MODEL_a1941c9d46b64972a2ec3ea1a12f568e",
            "value": " 1/1 [00:00&lt;00:00, 12.23it/s]"
          }
        },
        "9bafd9f7095945a6884f18c21e3d2ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445e85556b9940c8a6327f391c6f1445",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28dd0e44b2bd415392d8955deaaba5d0",
            "value": 1
          }
        },
        "a1941c9d46b64972a2ec3ea1a12f568e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a571e5d4de564cbeaad0094ff9726639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0494c2b5fa2f49669bd34b9641680121",
              "IPY_MODEL_9bafd9f7095945a6884f18c21e3d2ba0",
              "IPY_MODEL_8dae503195a64c099e70ef7d232e0f2c"
            ],
            "layout": "IPY_MODEL_d9aa9556a8cd435592534d5617818c82"
          }
        },
        "a7d84eaff9b04a19825c5e1325ad8f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad2a78246a954825b7fda05a6a2d30bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd1499d8f5eb451c88c4542dbc1eb1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c00ae83daba543a09fa8000c6e37f7e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cbb76dc9734911920a08cb644566e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_302d3aa25c4941579a398792f59727b8",
              "IPY_MODEL_d9cf8b7505dd420993f6769a8b1d2a7e",
              "IPY_MODEL_6715df5767e24ecfb87717e9a2a4e38d"
            ],
            "layout": "IPY_MODEL_765a998f3e5f4b28acc61b7d8ea3c853"
          }
        },
        "c4f00450e0c8475ab9a79788560e1b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9aa9556a8cd435592534d5617818c82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d9cf8b7505dd420993f6769a8b1d2a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2a78246a954825b7fda05a6a2d30bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd1499d8f5eb451c88c4542dbc1eb1c2",
            "value": 1
          }
        },
        "ed15d627de704879af025081685882c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff46e36ebbbe41f3baf52b4ea08628bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
